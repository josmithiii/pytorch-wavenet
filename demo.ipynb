{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from wavenet_model import *\n",
    "from audio_data import WavenetDataset\n",
    "from wavenet_training import *\n",
    "from model_logging import *\n",
    "#from optimizers import SGDNormalized\n",
    "from scipy.io import wavfile\n",
    "import torch\n",
    "#from Tensorboard import TensorboardLogger\n",
    "#from torch.utils.tensorboard import SummaryWriter as TensorboardLogger\n",
    "from model_logging import TensorboardLogger\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Update dtype based on device\n",
    "if device == \"cuda\":\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    ltype = torch.cuda.LongTensor\n",
    "elif device == \"mps\":\n",
    "    dtype = torch.FloatTensor\n",
    "    ltype = torch.LongTensor\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    ltype = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = WaveNetModel(layers=6,\n",
    "                     blocks=4,\n",
    "                     dilation_channels=16,\n",
    "                     residual_channels=16,\n",
    "                     skip_channels=32,\n",
    "                     output_length=8,\n",
    "                     dtype=dtype, \n",
    "                    bias=False)\n",
    "model = load_latest_model_from('snapshots', use_cuda=device)\n",
    "#model = torch.load('snapshots/saber_model_2017-12-18_20-47-36', map_location=lambda storage, loc: storage)\n",
    "model.dtype = dtype\n",
    "model = model.to(device)\n",
    "\n",
    "print('model: ', model)\n",
    "print('receptive field: ', model.receptive_field)\n",
    "print('parameter count: ', model.parameter_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = WavenetDataset(dataset_file='train_samples/saber/dataset.npz',\n",
    "data = WavenetDataset(dataset_file='train_samples/bach_chaconne/dataset.npz',\n",
    "                      item_length=model.receptive_field + model.output_length - 1,\n",
    "                      target_length=model.output_length,\n",
    "                      file_location='train_samples/saber',\n",
    "                      test_stride=20)\n",
    "print('the dataset has ' + str(len(data)) + ' items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_and_log_samples(step):\n",
    "    sample_length=4000\n",
    "    gen_model = load_latest_model_from('snapshots')\n",
    "    print(\"start generating...\")\n",
    "    samples = generate_audio(gen_model,\n",
    "                             length=sample_length,\n",
    "                             temperatures=[0])\n",
    "    tf_samples = tf.convert_to_tensor(samples, dtype=tf.float32)\n",
    "    logger.audio_summary('temperature 0', tf_samples, step, sr=16000)\n",
    "\n",
    "    samples = generate_audio(gen_model,\n",
    "                             length=sample_length,\n",
    "                             temperatures=[0.5])\n",
    "    tf_samples = tf.convert_to_tensor(samples, dtype=tf.float32)\n",
    "    logger.audio_summary('temperature 0.5', tf_samples, step, sr=16000)\n",
    "    print(\"audio clips generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = TensorboardLogger(log_interval=200,\n",
    "                           validation_interval=200,\n",
    "                           generate_interval=500,\n",
    "                           generate_function=generate_and_log_samples,\n",
    "                           log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WavenetDataset(dataset_file='train_samples/bach_chaconne/dataset.npz',\n",
    "                      item_length=model.receptive_field + model.output_length - 1,\n",
    "                      target_length=model.output_length,\n",
    "                      file_location='train_samples/bach_chaconne',\n",
    "                      test_stride=20)\n",
    "\n",
    "print('the dataset has ' + str(len(data)) + ' items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = WavenetTrainer(model=model,\n",
    "                        dataset=data,\n",
    "                        batch_size=8,\n",
    "                        val_batch_size=32,\n",
    "                        val_subset_size=500,\n",
    "                        lr=0.001,\n",
    "                        weight_decay=0.0,\n",
    "                        gradient_clipping=1,\n",
    "                        snapshot_interval=1000,\n",
    "                        val_interval=1000)\n",
    "# Create trainer with the modified dataset\n",
    "trainer_prv = WavenetTrainer(model=model,\n",
    "                        dataset=data,\n",
    "                        lr=0.001,\n",
    "                        # did not exist but we added it:\n",
    "                        weight_decay=0.0,\n",
    "                        gradient_clipping=None,\n",
    "                        # does not exist: snapshot_path='snapshots',\n",
    "                        # does not exist: snapshot_name='saber_model',\n",
    "                        snapshot_interval=100000,\n",
    "                        # does not exist: dtype=dtype,\n",
    "                        # does not exist: ltype=ltype\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update trainer to handle device properly\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield tuple(b.to(self.device) for b in batch)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "\n",
    "# Create trainer\n",
    "trainer = WavenetTrainer(model=model,\n",
    "                        dataset=data,\n",
    "                        lr=0.001,\n",
    "                        weight_decay=0.0,\n",
    "                        gradient_clipping=None,\n",
    "                        # snapshot_path='snapshots',\n",
    "                        # snapshot_name='saber_model',\n",
    "                        # snapshot_interval=100000\n",
    "                        )\n",
    "\n",
    "# Set up dataloader with device handling\n",
    "base_dataloader = torch.utils.data.DataLoader(dataset=data, \n",
    "                                            batch_size=8,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=0)\n",
    "trainer.dataloader = DeviceDataLoader(base_dataloader, device)\n",
    "\n",
    "print(\"Dataloader length:\", len(trainer.dataloader))\n",
    "print(\"Dataset total length:\", len(data))\n",
    "print(\"Dataset parameters:\")\n",
    "print(f\"  Item length: {data.item_length}\")\n",
    "print(f\"  Target length: {data.target_length}\")\n",
    "print(f\"  Test stride: {data._test_stride}\")\n",
    "print(f\"  Data shape: {data.data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('start training...')\n",
    "tic = time.time()\n",
    "trainer.train(epochs=20)\n",
    "toc = time.time()\n",
    "print('Training took {} seconds.'.format(toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.start_samples\n",
    "data.train = False\n",
    "trainer.dataloader.dataset.train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"dataloader length: \", len(trainer.dataloader))\n",
    "print(\"test length:\", len(data))\n",
    "print(\"sample length:\", data._length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.dtype = dtype\n",
    "print(model.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_data = data[100][0]\n",
    "start_data = torch.max(start_data, 0)[1]\n",
    "print(start_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prog_callback(step, total_steps):\n",
    "    print(str(100 * step // total_steps) + \"% generated\")\n",
    "for q in model.dilated_queues:\n",
    "    q.dtype = dtype\n",
    "    \n",
    "generated1 = model.generate_fast(num_samples=160000, \n",
    "                                 first_samples=start_data,\n",
    "                                 progress_callback=prog_callback,\n",
    "                                 progress_interval=1000,\n",
    "                                 temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(generated1, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(generated1); ax1.set_title('Raw audio signal')\n",
    "ax2.specgram(generated1); ax2.set_title('Spectrogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(start_sample); ax1.set_title('Raw audio signal')\n",
    "ax2.specgram(start_sample); ax2.set_title('Spectrogram');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start training...\n",
    "epoch 0\n",
    "loss at step 50: 5.601520707905292\n",
    "one training step does take approximately 0.19061788082122802 seconds)\n",
    "loss at step 100: 5.552221384048462\n",
    "loss at step 150: 5.544267034530639\n",
    "loss at step 200: 5.531772727966309\n",
    "validation loss: 5.490092188517252\n",
    "validation accuracy: 1.0451505016722409%\n",
    "loss at step 250: 5.524168214797974\n",
    "loss at step 300: 5.501959915161133\n",
    "loss at step 350: 5.440135269165039\n",
    "loss at step 400: 5.332433271408081\n",
    "validation loss: 4.427264089584351\n",
    "validation accuracy: 24.91638795986622%\n",
    "loss at step 450: 5.3144251728057865\n",
    "loss at step 500: 5.112221040725708\n",
    "loss at step 550: 5.0085866355896\n",
    "loss at step 600: 4.963179755210876\n",
    "validation loss: 3.9374835840861\n",
    "validation accuracy: 25.22993311036789%\n",
    "loss at step 650: 4.930944819450378\n",
    "loss at step 700: 4.881737098693848\n",
    "loss at step 750: 4.742912063598633\n",
    "loss at step 800: 4.686616892814636\n",
    "validation loss: 3.8073496564229328\n",
    "validation accuracy: 25.68979933110368%\n",
    "loss at step 850: 4.577959842681885\n",
    "loss at step 900: 4.399262466430664\n",
    "loss at step 950: 4.375202603340149\n",
    "loss at step 1000: 4.3079585933685305\n",
    "validation loss: 3.5753333044052122\n",
    "validation accuracy: 24.498327759197323%\n",
    "loss at step 1050: 4.244945120811463\n",
    "loss at step 1100: 4.123299965858459\n",
    "loss at step 1150: 4.103064022064209\n",
    "loss at step 1200: 4.082510600090027\n",
    "validation loss: 3.413504378000895\n",
    "validation accuracy: 26.00334448160535%\n",
    "loss at step 1250: 3.939071798324585\n",
    "loss at step 1300: 3.9508083343505858\n",
    "loss at step 1350: 3.8663349866867067\n",
    "loss at step 1400: 3.8707763385772704\n",
    "validation loss: 3.2716021649042766\n",
    "validation accuracy: 25.020903010033447%\n",
    "epoch 1\n",
    "loss at step 1450: 3.7944415807724\n",
    "loss at step 1500: 3.82066180229187\n",
    "loss at step 1550: 3.8355930709838866\n",
    "loss at step 1600: 3.7929911947250368\n",
    "validation loss: 3.1106809441248577\n",
    "validation accuracy: 27.38294314381271%\n",
    "loss at step 1650: 3.761087512969971\n",
    "loss at step 1700: 3.7161417627334594\n",
    "loss at step 1750: 3.68661922454834\n",
    "loss at step 1800: 3.5772906827926634\n",
    "validation loss: 2.9680276489257813\n",
    "validation accuracy: 28.38628762541806%\n",
    "loss at step 1850: 3.653769178390503\n",
    "loss at step 1900: 3.8210517024993895\n",
    "loss at step 1950: 3.4200775527954104\n",
    "loss at step 2000: 3.5994531393051146\n",
    "validation loss: 2.997499696413676\n",
    "validation accuracy: 28.365384615384613%\n",
    "loss at step 2050: 3.5013914012908938\n",
    "loss at step 2100: 3.3859068155288696\n",
    "loss at step 2150: 3.4870605945587156\n",
    "loss at step 2200: 3.382463240623474\n",
    "validation loss: 2.9953096040089924\n",
    "validation accuracy: 28.010033444816052%\n",
    "loss at step 2250: 3.2740977144241334\n",
    "loss at step 2300: 3.3375968599319457\n",
    "loss at step 2350: 3.33543728351593\n",
    "loss at step 2400: 3.311717290878296\n",
    "validation loss: 2.741686725616455\n",
    "validation accuracy: 29.15969899665552%\n",
    "loss at step 2450: 3.3888323879241944\n",
    "loss at step 2500: 3.2774668455123903\n",
    "loss at step 2550: 3.2909540367126464\n",
    "loss at step 2600: 3.156819558143616\n",
    "validation loss: 2.644340982437134\n",
    "validation accuracy: 29.38963210702341%\n",
    "loss at step 2650: 3.1362243604660036\n",
    "loss at step 2700: 3.1809526824951173\n",
    "loss at step 2750: 3.1044933462142943\n",
    "loss at step 2800: 3.2104168224334715\n",
    "validation loss: 2.710980224609375\n",
    "validation accuracy: 28.511705685618725%\n",
    "epoch 2\n",
    "loss at step 2850: 3.1645427131652832\n",
    "loss at step 2900: 3.086708178520203\n",
    "loss at step 2950: 3.1935667037963866\n",
    "loss at step 3000: 3.065649948120117\n",
    "validation loss: 2.599242707888285\n",
    "validation accuracy: 29.95401337792642%\n",
    "loss at step 3050: 2.9623973870277407\n",
    "loss at step 3100: 2.977948703765869\n",
    "loss at step 3150: 3.039284749031067\n",
    "loss at step 3200: 3.1032708168029783\n",
    "validation loss: 2.5787479861577354\n",
    "validation accuracy: 30.0376254180602%\n",
    "loss at step 3250: 3.020424065589905\n",
    "loss at step 3300: 2.9368478298187255\n",
    "loss at step 3350: 3.011261811256409\n",
    "loss at step 3400: 2.936244683265686\n",
    "validation loss: 2.510010568300883\n",
    "validation accuracy: 30.56020066889632%\n",
    "loss at step 3450: 2.92849506855011\n",
    "loss at step 3500: 2.903533215522766\n",
    "loss at step 3550: 2.835393509864807\n",
    "loss at step 3600: 2.875207557678223\n",
    "validation loss: 2.5806426111857097\n",
    "validation accuracy: 29.995819397993312%\n",
    "loss at step 3650: 2.982465934753418\n",
    "loss at step 3700: 2.8224086570739746\n",
    "loss at step 3750: 2.773958697319031\n",
    "loss at step 3800: 2.933848671913147\n",
    "validation loss: 2.429751847585042\n",
    "validation accuracy: 31.47993311036789%\n",
    "loss at step 3850: 2.935438051223755\n",
    "loss at step 3900: 2.8551607513427735\n",
    "loss at step 3950: 2.7788655376434326\n",
    "loss at step 4000: 2.7510599946975707\n",
    "validation loss: 2.3318386379877727\n",
    "validation accuracy: 31.25%\n",
    "loss at step 4050: 2.7630084943771362\n",
    "loss at step 4100: 2.784786548614502\n",
    "loss at step 4150: 2.823610978126526\n",
    "loss at step 4200: 2.74433349609375\n",
    "validation loss: 2.3619025961558022\n",
    "validation accuracy: 31.08277591973244%\n",
    "loss at step 4250: 2.7720167875289916\n",
    "epoch 3\n",
    "loss at step 4300: 2.722008581161499\n",
    "loss at step 4350: 2.683127827644348\n",
    "loss at step 4400: 2.7036391639709474\n",
    "validation loss: 2.3295965019861855\n",
    "validation accuracy: 31.709866220735787%\n",
    "loss at step 4450: 2.5949549078941345\n",
    "loss at step 4500: 2.6527379083633424\n",
    "loss at step 4550: 2.6835867977142334\n",
    "loss at step 4600: 2.6377884101867677\n",
    "validation loss: 2.428244962692261\n",
    "validation accuracy: 31.438127090301005%\n",
    "loss at step 4650: 2.682296323776245\n",
    "loss at step 4700: 2.6830776596069335\n",
    "loss at step 4750: 2.7608815002441407\n",
    "loss at step 4800: 2.5994027352333067\n",
    "validation loss: 2.2691842166582745\n",
    "validation accuracy: 32.002508361204015%\n",
    "loss at step 4850: 2.6003666806221006\n",
    "loss at step 4900: 2.7449550104141234\n",
    "loss at step 4950: 2.6577998113632204\n",
    "loss at step 5000: 2.593499083518982\n",
    "validation loss: 2.2588222297032674\n",
    "validation accuracy: 31.960702341137125%\n",
    "loss at step 5050: 2.6504480028152466\n",
    "loss at step 5100: 2.692755765914917\n",
    "loss at step 5150: 2.646983962059021\n",
    "loss at step 5200: 2.5553077936172484\n",
    "validation loss: 2.235258067448934\n",
    "validation accuracy: 33.61204013377927%\n",
    "loss at step 5250: 2.5953399658203127\n",
    "loss at step 5300: 2.77093816280365\n",
    "loss at step 5350: 2.628749816417694\n",
    "loss at step 5400: 2.558472900390625\n",
    "validation loss: 2.253657941818237\n",
    "validation accuracy: 33.27759197324415%\n",
    "loss at step 5450: 2.6695416879653933\n",
    "loss at step 5500: 2.6403193950653074\n",
    "loss at step 5550: 2.6906979990005495\n",
    "loss at step 5600: 2.632576594352722\n",
    "validation loss: 2.2271932284037272\n",
    "validation accuracy: 32.29515050167224%\n",
    "loss at step 5650: 2.6107604622840883\n",
    "epoch 4\n",
    "loss at step 5700: 2.582443132400513\n",
    "loss at step 5750: 2.6650914669036867\n",
    "loss at step 5800: 2.8158610439300538\n",
    "validation loss: 2.228590728441874\n",
    "validation accuracy: 33.34030100334448%\n",
    "loss at step 5850: 2.6931549406051634\n",
    "loss at step 5900: 2.651780562400818\n",
    "loss at step 5950: 2.750603561401367\n",
    "loss at step 6000: 2.722158169746399\n",
    "validation loss: 3.0212835629781085\n",
    "validation accuracy: 30.748327759197323%\n",
    "loss at step 6050: 2.6879207038879396\n",
    "loss at step 6100: 2.6904709482192994\n",
    "loss at step 6150: 2.6776280212402344\n",
    "loss at step 6200: 2.7096633672714234\n",
    "validation loss: 2.599953867594401\n",
    "validation accuracy: 32.98494983277592%\n",
    "loss at step 6250: 2.634800329208374\n",
    "loss at step 6300: 2.6009347152709963\n",
    "loss at step 6350: 2.628697416782379\n",
    "loss at step 6400: 2.7100318574905398\n",
    "validation loss: 2.356964473724365\n",
    "validation accuracy: 33.570234113712374%\n",
    "loss at step 6450: 2.782756748199463\n",
    "loss at step 6500: 2.7148419046401977\n",
    "loss at step 6550: 2.64122682094574"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "env_pytorch_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
