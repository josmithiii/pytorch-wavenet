{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from wavenet_model import *\n",
    "from audio_data import WavenetDataset\n",
    "from wavenet_training import *\n",
    "from model_logging import *\n",
    "from scipy.io import wavfile\n",
    "import torch\n",
    "import numpy as np\n",
    "from model_logging import TensorboardLogger\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Debug printing function\n",
    "debug_enabled = False\n",
    "def debug_print(msg):\n",
    "    if debug_enabled:\n",
    "        print(msg)\n",
    "\n",
    "def set_debug(enabled):\n",
    "    global debug_enabled\n",
    "    debug_enabled = enabled\n",
    "\n",
    "# Set debug printing off by default\n",
    "set_debug(False)\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "# Check device availability\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS built: {torch.backends.mps.is_built()}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory dataset for better performance\n",
    "class MemoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.length = len(dataset)\n",
    "        self.train = dataset.train if hasattr(dataset, 'train') else True\n",
    "\n",
    "        # Print sample item shape during initialization\n",
    "        sample_item = self.dataset[0]\n",
    "        print(\"\\nDataset sample info:\")\n",
    "        print(f\"Sample item type: {type(sample_item)}\")\n",
    "        if isinstance(sample_item, tuple):\n",
    "            print(f\"Sample x shape: {sample_item[0].shape}\")\n",
    "            print(f\"Sample target shape: {sample_item[1].shape}\")\n",
    "        else:\n",
    "            print(f\"Sample shape: {sample_item.shape}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        # Print shape occasionally for debugging\n",
    "        if idx % 1000 == 0 and debug_enabled:\n",
    "            if isinstance(item, tuple):\n",
    "                print(f\"\\nBatch {idx} shapes:\")\n",
    "                print(f\"x: {item[0].shape}\")\n",
    "                print(f\"target: {item[1].shape}\")\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = WaveNetModel(layers=6,\n",
    "                     blocks=4,\n",
    "                     dilation_channels=16,\n",
    "                     residual_channels=16,\n",
    "                     skip_channels=32,\n",
    "                     output_length=8,\n",
    "                     bias=False)\n",
    "\n",
    "# Load latest model if available\n",
    "model = load_latest_model_from('snapshots', use_cuda=False)\n",
    "\n",
    "# Ensure model is on correct device\n",
    "model = model.to(device)\n",
    "print(f\"Model device after transfer: {next(model.parameters()).device}\")\n",
    "print(f\"Start conv weight device: {model.start_conv.weight.device}\")\n",
    "\n",
    "print('model: ', model)\n",
    "print('receptive field: ', model.receptive_field)\n",
    "print('parameter count: ', model.parameter_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "data = WavenetDataset(dataset_file='train_samples/bach_chaconne/dataset.npz',\n",
    "                      item_length=model.receptive_field + model.output_length - 1,\n",
    "                      target_length=model.output_length,\n",
    "                      file_location='train_samples/bach_chaconne',\n",
    "                      test_stride=20)\n",
    "\n",
    "# Load dataset file and print info\n",
    "print(\"Loading dataset file:\", data.dataset_file)\n",
    "with np.load(data.dataset_file) as dataset:\n",
    "    print(\"Available keys in dataset:\", dataset.files)\n",
    "    data.data = dataset['arr_0']\n",
    "\n",
    "print('the dataset has ' + str(len(data)) + ' items')\n",
    "print(f\"Dataset type: {type(data.data)}\")\n",
    "print(f\"Dataset shape: {data.data.shape}\")\n",
    "print(f\"Dataset dtype: {data.data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create memory dataset for better performance\n",
    "memory_dataset = MemoryDataset(data)\n",
    "\n",
    "# Create trainer with memory_dataset\n",
    "trainer = WavenetTrainer(\n",
    "    model=model,\n",
    "    dataset=memory_dataset,\n",
    "    batch_size=32, # JOS: was 8, then 16\n",
    "    val_batch_size=32, # JOS: was 32\n",
    "    val_subset_size=1000,  # Increased from 500\n",
    "    lr=0.0005,  # Reduced from 0.001\n",
    "    weight_decay=0.01,  # Added L2 regularization\n",
    "    gradient_clipping=1,\n",
    "    snapshot_interval=500,  # was 1000\n",
    "    snapshot_path='snapshots',\n",
    "    val_interval=1000,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_log_samples(model, step, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate audio samples and prepare them for logging.\n",
    "    Args:\n",
    "        model: The trained WaveNet model\n",
    "        step: Current training step (for logging)\n",
    "        temperature: Controls randomness in generation\n",
    "    Returns:\n",
    "        Dictionary containing the generated audio data\n",
    "    \"\"\"\n",
    "    # Generate samples\n",
    "    samples = generate_audio(model, length=16000, temperature=temperature)\n",
    "    \n",
    "    # Create a dictionary with the samples\n",
    "    data = {\n",
    "        'temperature': temperature,\n",
    "        'samples': samples,\n",
    "        'step': step,\n",
    "        'sample_rate': 16000\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Set up TensorboardLogger\n",
    "try:\n",
    "    logger = TensorboardLogger(log_interval=200,\n",
    "                            validation_interval=200,\n",
    "                            generate_interval=500,\n",
    "                            generate_function=generate_and_log_samples,\n",
    "                            log_dir=\"logs\")\n",
    "    print(\"TensorboardLogger initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing TensorboardLogger: {e}\")\n",
    "    print(\"Continuing without logging...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated generate_audio function\n",
    "def generate_audio(model, length=16000, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate audio samples using the trained model.\n",
    "    Args:\n",
    "        model: Trained WaveNet model\n",
    "        length: Number of samples to generate\n",
    "        temperature: Controls randomness (higher = more random, lower = more deterministic)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    # Move model to device if not already\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Start with zeros and convert to one-hot encoding\n",
    "    current_sample = torch.zeros(1, 256, model.receptive_field).to(device)\n",
    "    generated_samples = []\n",
    "\n",
    "    print(f\"\\nGenerating {length} samples...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # We need to generate samples in chunks since the model outputs multiple samples at once\n",
    "        for i in tqdm(range(0, length, model.output_length)):\n",
    "            # Get model prediction\n",
    "            output = model(current_sample)\n",
    "            \n",
    "            # Reshape output to [batch_size, output_length, num_classes]\n",
    "            output = output.view(1, model.output_length, 256)\n",
    "            \n",
    "            # Apply temperature\n",
    "            if temperature != 1:\n",
    "                output = output / temperature\n",
    "\n",
    "            # Process each output step\n",
    "            for j in range(min(model.output_length, length - i)):\n",
    "                # Get probabilities for current timestep\n",
    "                probabilities = F.softmax(output[0, j], dim=0)\n",
    "                \n",
    "                # Sample from the output distribution\n",
    "                next_sample_idx = torch.multinomial(probabilities, 1).item()\n",
    "                \n",
    "                # Append to generated samples\n",
    "                generated_samples.append(next_sample_idx)\n",
    "                \n",
    "                # Create one-hot encoding for the new sample\n",
    "                if j < model.output_length - 1 or i + model.output_length < length:\n",
    "                    next_sample_onehot = torch.zeros(1, 256, 1).to(device)\n",
    "                    next_sample_onehot[0, next_sample_idx, 0] = 1\n",
    "                    \n",
    "                    # Shift input window and add new sample\n",
    "                    current_sample = torch.roll(current_sample, -1, dims=2)\n",
    "                    current_sample[:, :, -1] = next_sample_onehot.squeeze(-1)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    samples = np.array(generated_samples, dtype=np.int16)\n",
    "\n",
    "    # Scale back to audio range\n",
    "    samples = samples - 128\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up TensorboardLogger\n",
    "try:\n",
    "    logger = TensorboardLogger(log_interval=200,\n",
    "                            validation_interval=200,\n",
    "                            generate_interval=500,\n",
    "                            generate_function=generate_and_log_samples,\n",
    "                            log_dir=\"logs\")\n",
    "    print(\"TensorboardLogger initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing TensorboardLogger: {e}\")\n",
    "    print(\"Continuing without logging...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start training with error handling\n",
    "print('\\nStarting training...')\n",
    "tic = time.time()\n",
    "try:\n",
    "    trainer.train(epochs=8) # JOS: was 20\n",
    "    # print(\"TRAINING DISABLED\")\n",
    "    pass\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during training:\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {str(e)}\")\n",
    "    print(f\"Model device: {next(model.parameters()).device}\")\n",
    "    raise\n",
    "toc = time.time()\n",
    "print('Training took {} seconds.'.format(toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "print('Training took more than {} seconds.'.format(toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set to evaluation mode\n",
    "memory_dataset.train = False\n",
    "trainer.dataloader.dataset.train = False\n",
    "\n",
    "print(\"Dataloader length:\", len(trainer.dataloader))\n",
    "print(\"Test dataset length:\", len(memory_dataset))\n",
    "print(\"Sample length:\", data.item_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate audio samples\n",
    "# Get a starting sample from the dataset\n",
    "start_data = data[100][0]\n",
    "start_data = torch.max(start_data, 0)[1]\n",
    "print(\"Starting data shape:\", start_data.shape)\n",
    "print(\"Starting data sample:\", start_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Progress callback for generation\n",
    "def prog_callback(step, total_steps):\n",
    "    print(str(100 * step // total_steps) + \"% generated\")\n",
    "\n",
    "model = load_latest_model_from('snapshots')\n",
    "model = model.to(device)\n",
    "\n",
    "# Get a starting sample from the dataset\n",
    "start_data = data[100][0]\n",
    "start_data = torch.max(start_data, 0)[1]\n",
    "print(\"Starting data shape:\", start_data.shape)\n",
    "print(\"Starting data sample:\", start_data)\n",
    "\n",
    "# Make sure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Use the simpler generate_audio function instead of generate_fast\n",
    "print(\"\\nGenerating audio samples...\")\n",
    "generated1 = generate_audio(model, length=160000, temperature=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Play the generated audio\n",
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(generated1, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the generated audio\n",
    "output_file = \"generated_audio.wav\"\n",
    "wavfile.write(output_file, 16000, generated1)\n",
    "print(f\"Generated audio saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the generated audio\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(generated1); ax1.set_title('Raw audio signal')\n",
    "ax2.specgram(generated1, Fs=16000); ax2.set_title('Spectrogram');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "env_pytorch_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
