# pytorch-wavenet
This is an implementation of the WaveNet architecture, as described in the [original paper](https://arxiv.org/abs/1609.03499).

## Features
- Automatic creation of a dataset (training and validation/test set) from all sound files (.wav, .aiff, .mp3) in a directory
- Efficient multithreaded data loading
- Logging to TensorBoard (Training loss, validation loss, validation accuracy, parameter and gradient histograms, generated samples)
- Fast generation, as introduced [here](https://arxiv.org/abs/1611.09482)

## Requirements
- python 3
- pytorch 0.3
- numpy
- librosa
- jupyter
- tensorflow for TensorBoard logging

## Demo
For an introduction on how to use this model, take a look at the [WaveNet demo notebook](https://github.com/vincentherrmann/pytorch-wavenet/blob/master/WaveNet_demo.ipynb). 
You can find audio clips generated by a simple trained model in the [generated samples directory](https://github.com/vincentherrmann/pytorch-wavenet/tree/master/generated_samples)

## Demo 2 (JOS)
* `python demo.py --mode train --epochs 8`
  - `tensorboard --logdir=runs`
  - Open http://localhost:6006 in your browser
  - `python demo.py --resume ...` to resume from checkpoint

* `python demo.py --mode generate --length 1000`

## Detailed Small Training Run
* `python demo.py --mode train --epochs 1 --layers 4 --blocks 2 --dilation-channels 16 --residual-channels 16 --skip-channels 32 --output-length 8 --start-fresh`
